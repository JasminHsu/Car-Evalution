{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caaf154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import model_selection, linear_model, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve, \\\n",
    "StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, average_precision_score, roc_curve, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca010c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c891f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "car = pd.read_csv('car.data', names=['buying','maint','doors','persons','lug_boot','safety','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf00f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dummy variable\n",
    "X = pd.get_dummies(car.iloc[:,:6])\n",
    "y = car['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bc23d",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f93f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=45)\n",
    "f_measure_score_c = {'decision_tree':{},'knn':{},'logistic':{},'NB':{},'svm':{}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e664d1",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f645b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    }
   ],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "param_dict={'criterion':['gini','entropy'], 'max_depth':range(1,11), 'min_samples_leaf':range(1,5), \n",
    "            'min_samples_split':range(1,10)} \n",
    "d_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_tree = GridSearchCV(d_tree, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_tree.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "nested_score_tree = cross_val_score(grid_tree, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['decision_tree']['mean'] = np.mean(nested_score_tree)\n",
    "f_measure_score_c['decision_tree']['std'] = np.std(nested_score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358a29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.94      0.88      0.91       129\n",
      "        good       0.73      0.95      0.83        20\n",
      "       unacc       0.98      0.99      0.99       397\n",
      "       vgood       0.83      0.80      0.82        25\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2fdc73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b05036",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b284f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'C':[0.0001,0.001, 0.01, 1, 0.1, 10, 100, 1000], 'penalty':['l1','l2'],\n",
    "              'solver':['lbfgs','sag','saga','newton-cg']}\n",
    "\n",
    "logistic = linear_model.LogisticRegression(random_state=42)\n",
    "\n",
    "grid_log = GridSearchCV(logistic, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = grid_log.predict(X_test)\n",
    "nested_score_log = cross_val_score(grid_log, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['logistic']['mean'] = np.mean(nested_score_log)\n",
    "f_measure_score_c['logistic']['std'] = np.std(nested_score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590de22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.91      0.82      0.86       129\n",
      "        good       0.72      0.90      0.80        20\n",
      "       unacc       0.97      0.97      0.97       397\n",
      "       vgood       0.80      0.96      0.87        25\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.85      0.91      0.88       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_log),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097efa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'penalty': 'l1', 'solver': 'saga'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_log.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8a638",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4cece7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'n_neighbors':list(range(1,31)), 'weights':['uniform', 'distance']}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred_knn = grid_knn.predict(X_test)\n",
    "nested_score_knn = cross_val_score(grid_knn, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['knn']['mean'] = np.mean(nested_score_knn)\n",
    "f_measure_score_c['knn']['std'] = np.std(nested_score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4285442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.80      0.86      0.83       129\n",
      "        good       0.57      0.20      0.30        20\n",
      "       unacc       0.96      0.99      0.98       397\n",
      "       vgood       0.93      0.56      0.70        25\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.82      0.65      0.70       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1135fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9, 'weights': 'distance'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6d6a2",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa31f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "nested_score_nb = cross_val_score(nb, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['NB']['mean'] = np.mean(nested_score_nb)\n",
    "f_measure_score_c['NB']['std'] = np.std(nested_score_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ef33bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.59      0.77      0.67       129\n",
      "        good       0.44      0.85      0.58        20\n",
      "       unacc       1.00      0.83      0.90       397\n",
      "       vgood       0.68      1.00      0.81        25\n",
      "\n",
      "    accuracy                           0.82       571\n",
      "   macro avg       0.68      0.86      0.74       571\n",
      "weighted avg       0.87      0.82      0.84       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_nb),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff1da7",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aeb906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'C':[0.1,1,100,1000],'kernel':['rbf','linear'], 'gamma':[1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "grid_svm = GridSearchCV(svm, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "nested_score_svm = cross_val_score(grid_svm, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['svm']['mean'] = np.mean(nested_score_svm)\n",
    "f_measure_score_c['svm']['std'] = np.std(nested_score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "072f8626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.98      0.97      0.98       129\n",
      "        good       0.86      0.95      0.90        20\n",
      "       unacc       1.00      1.00      1.00       397\n",
      "       vgood       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.96      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_svm),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cf639b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8c77e",
   "metadata": {},
   "source": [
    "### Models Comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0713dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree :  {'mean': 0.972788681274365, 'std': 0.011899684402510432}\n",
      "knn :  {'mean': 0.9317112515123, 'std': 0.0171712971111848}\n",
      "logistic :  {'mean': 0.9346014249227046, 'std': 0.01830887424272436}\n",
      "NB :  {'mean': 0.8026582874042208, 'std': 0.03286866941083019}\n",
      "svm :  {'mean': 0.9982591746202447, 'std': 0.0026591688489214986}\n"
     ]
    }
   ],
   "source": [
    "for a,b in f_measure_score_c.items():\n",
    "    print(a, ': ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8a5d9",
   "metadata": {},
   "source": [
    "#### Result: SVM outperformed other models.  I used it as my final model to further know the hyperparameter and performance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d261a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "best params:  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "best score:  0.9982683658170914\n",
      "[[125   3   0   1]\n",
      " [  0  19   0   1]\n",
      " [  0   0 397   0]\n",
      " [  2   0   0  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.98      0.97      0.98       129\n",
      "        good       0.86      0.95      0.90        20\n",
      "       unacc       1.00      1.00      1.00       397\n",
      "       vgood       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.96      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_svm.fit(X_train, y_train)\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "print('best params: ', grid_svm.best_params_)\n",
    "print('best score: ', grid_svm.best_score_)\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
